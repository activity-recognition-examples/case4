{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1338)\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "cmap_group = plt.cm.Paired\n",
    "cmap_y = plt.cm.coolwarm\n",
    "\n",
    "def visualize_groups(classes, groups):\n",
    "    # Visualize dataset groups\n",
    "    fig, ax = plt.subplots(dpi=200) \n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [0.5] * len(groups),\n",
    "        c=groups,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [3.5] * len(groups),\n",
    "        c=classes,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.set(\n",
    "        ylim=[-1, 5],\n",
    "        yticks=[0.5, 3.5],\n",
    "        yticklabels=[\"Data\\ngroup\", \"Data\\nclass\"],\n",
    "        xlabel=\"Sample index\",\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=indices,\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "            cmap=cmap_cv,\n",
    "            vmin=-0.2,\n",
    "            vmax=1.2,\n",
    "        )\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data \n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 2.5] * len(X), c=group, marker=\"_\", lw=lw, cmap=cmap_data \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + [\"class\", \"group\"]\n",
    "    ax.set(\n",
    "        yticks=np.arange(n_splits + 2) + 0.5,\n",
    "        yticklabels=yticklabels,\n",
    "        xlabel=\"Sample index\",\n",
    "        ylabel=\"CV iteration\",\n",
    "        ylim=[n_splits + 2.2, -0.2],\n",
    "        xlim=[0, len(X)],\n",
    "    )\n",
    "    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_segments(data, target_x, target_y, target_group,  window_size=80, step_size=40):\n",
    "    segments = []\n",
    "    labels = []\n",
    "    group = []\n",
    "\n",
    "    for i in range(0, len(data) - window_size, step_size):\n",
    "        segments_data = []\n",
    "        for x in target_x:\n",
    "            x_values = data[x].values[i:i + window_size]\n",
    "            segments_data.append(x_values)\n",
    "        label = data[target_y].values[i]\n",
    "        member = data[target_group].values[i]\n",
    "\n",
    "        segments.append(segments_data)\n",
    "        labels.append(label)\n",
    "        group.append(member)\n",
    "    return segments, labels, group\n",
    "\n",
    "\n",
    "def create_label_segments(data, target, window_size=80, step_size=40):\n",
    "    ys = []\n",
    "    for i in range(0, len(data) - window_size, step_size):\n",
    "        segments_data = []\n",
    "        y = data[target].values[i]\n",
    "        y.append(y)\n",
    "    return ys\n",
    "\n",
    "\n",
    "def extract_time_features(segments):\n",
    "    features = []\n",
    "    for segment in segments:\n",
    "        segment_features = []\n",
    "        for axis in segment:\n",
    "            mean_axis = np.mean(axis)\n",
    "            std_axis = np.std(axis)\n",
    "            segment_features.extend([mean_axis, std_axis])\n",
    "        features.append(segment_features)\n",
    "    return np.array(features)\n",
    "\n",
    "def extract_frequency_features(segments, sampling_rate=100):\n",
    "    features = []\n",
    "    for segment in segments:\n",
    "        segment_features = []\n",
    "        for axis in segment:\n",
    "            fft_axis = np.abs(fft(axis))\n",
    "\n",
    "            # Peak frequency and maximum amplitude\n",
    "            peak_indices, _ = find_peaks(fft_axis)\n",
    "\n",
    "            if len(peak_indices) > 0:\n",
    "                peak_freq = peak_indices[np.argmax(fft_axis[peak_indices])] / len(axis) * sampling_rate\n",
    "                max_amplitude = np.max(fft_axis[peak_indices])\n",
    "            else:\n",
    "                peak_freq = 0.0  # デフォルトの値を設定\n",
    "                max_amplitude = 0.0  # デフォルトの値を設定\n",
    "\n",
    "            # Signal energy\n",
    "            energy = np.sum(axis ** 2) / len(axis)\n",
    "\n",
    "            segment_features.extend([peak_freq, max_amplitude, energy])\n",
    "\n",
    "        features.append(segment_features)\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トイデータの読み込み\n",
    "data = pd.read_csv('04_zel_toy_dataset.csv', index_col=0)\n",
    "\n",
    "# 欠損値の除去\n",
    "data.dropna(axis=0, how=\"any\", inplace=True)\n",
    "\n",
    "# セグメントを用意し、時間領域の特徴量と周波数領域の特徴量を抽出\n",
    "window_size = 80\n",
    "step_size = 40\n",
    "target_x = ['Solar.A','Solar.B','Piezo']\n",
    "target_y = \"place\" \n",
    "terget_group = \"user_id\"\n",
    "target_names = list(data[target_y].unique())\n",
    "\n",
    "# ラベルエンコーダーのインスタンス化\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "le3 = LabelEncoder()\n",
    "data[\"action\"] = le1.fit_transform(data[\"action\"])\n",
    "data[\"place\"] = le2.fit_transform(data[\"place\"])\n",
    "data[\"user_id\"] = le3.fit_transform(data[\"user_id\"])\n",
    "\n",
    "segments, labels, groups = create_segments(data, target_x, target_y, terget_group, window_size, step_size)\n",
    "\n",
    "time_features = extract_time_features(segments)\n",
    "frequency_features = extract_frequency_features(segments)\n",
    "\n",
    "# 時間領域の特徴量と周波数領域の特徴量を統合\n",
    "combined_features = np.concatenate((time_features, frequency_features), axis=1)\n",
    "\n",
    "# データセットの分割\n",
    "X = combined_features\n",
    "y = np.asarray(labels, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムフォレスト分類器をインスタンス化\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509693996729736\n",
      "0.5134734239802224\n",
      "0.7057692307692308\n",
      "0.6502183406113538\n",
      "0.8100734522560336\n",
      "0.5591160220994476\n",
      "0.6317147548674642\n",
      "0.4639097744360902\n",
      "0.6835886214442013\n",
      "0.6743951612903226\n",
      "0.5817137809187279\n"
     ]
    }
   ],
   "source": [
    "# LeaveOneGroupOutのインスタンスを作成\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "# 分割数、ここでは5分割\n",
    "for train_index, test_index in logo.split(X, y, groups):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "\n",
    "    # モデルの学習\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # 予測\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # 保存\n",
    "    all_y_true.extend(y_test)\n",
    "    all_y_pred.extend(y_pred)\n",
    "    \n",
    "    # 予測結果の評価（ここでは正解率）\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[4837 1434   20  109   88  877 1464]\n",
      " [ 762 2721   19  881   76  346  291]\n",
      " [  59  103  502   39  121  605   37]\n",
      " [  64  669   11 2360   19    7  251]\n",
      " [  53   77   43   69 8834 1703   41]\n",
      " [ 381  180  147   14 1315 6658  385]\n",
      " [1631  619   30 1098   84 1380 1783]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         lab       0.62      0.55      0.58      8829\n",
      "        hall       0.47      0.53      0.50      5096\n",
      "    elevator       0.65      0.34      0.45      1466\n",
      "      stairs       0.52      0.70      0.59      3381\n",
      "    outdoors       0.84      0.82      0.83     10820\n",
      "       store       0.58      0.73      0.64      9080\n",
      "      toilet       0.42      0.27      0.33      6625\n",
      "\n",
      "    accuracy                           0.61     45297\n",
      "   macro avg       0.58      0.56      0.56     45297\n",
      "weighted avg       0.61      0.61      0.60     45297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_y_true = le2.inverse_transform(np.array(all_y_true).astype(np.int32))\n",
    "all_y_pred = le2.inverse_transform(np.array(all_y_pred).astype(np.int32))\n",
    "\n",
    "# 全ユーザの結果に基づく混同行列と分類レポートを表示\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_y_true, all_y_pred, labels=target_names))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_y_true, all_y_pred, labels=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score for group 0: 0.8553092182030338\n",
      "Test score for group 0: 0.897196261682243\n",
      "Test score for group 0: 0.8960280373831776\n",
      "Test score for group 0: 0.8212616822429907\n",
      "Test score for group 0: 0.7091121495327103\n",
      "Test score for group 1: 0.7688504326328801\n",
      "Test score for group 1: 0.9517923362175525\n",
      "Test score for group 1: 0.8726823238566132\n",
      "Test score for group 1: 0.9480840543881335\n",
      "Test score for group 1: 0.7552533992583437\n",
      "Test score for group 2: 0.7991452991452992\n",
      "Test score for group 2: 0.8301282051282052\n",
      "Test score for group 2: 0.8675213675213675\n",
      "Test score for group 2: 0.8643162393162394\n",
      "Test score for group 2: 0.7574786324786325\n",
      "Test score for group 3: 0.7663755458515283\n",
      "Test score for group 3: 0.8766375545851528\n",
      "Test score for group 3: 0.7729257641921398\n",
      "Test score for group 3: 0.9072052401746725\n",
      "Test score for group 3: 0.8034934497816594\n",
      "Test score for group 4: 0.8391608391608392\n",
      "Test score for group 4: 0.965034965034965\n",
      "Test score for group 4: 0.9702797202797203\n",
      "Test score for group 4: 0.9545454545454546\n",
      "Test score for group 4: 0.8441330998248686\n",
      "Test score for group 5: 0.7082872928176795\n",
      "Test score for group 5: 0.8342541436464088\n",
      "Test score for group 5: 0.6939226519337016\n",
      "Test score for group 5: 0.7392265193370166\n",
      "Test score for group 5: 0.7513812154696132\n",
      "Test score for group 6: 0.8417350527549824\n",
      "Test score for group 6: 0.9144196951934349\n",
      "Test score for group 6: 0.9577960140679953\n",
      "Test score for group 6: 0.8744131455399061\n",
      "Test score for group 6: 0.778169014084507\n",
      "Test score for group 7: 0.6428571428571429\n",
      "Test score for group 7: 0.8345864661654135\n",
      "Test score for group 7: 0.6879699248120301\n",
      "Test score for group 7: 0.7706766917293233\n",
      "Test score for group 7: 0.7142857142857143\n",
      "Test score for group 8: 0.5908096280087527\n",
      "Test score for group 8: 0.8829321663019694\n",
      "Test score for group 8: 0.7680525164113785\n",
      "Test score for group 8: 0.7932166301969366\n",
      "Test score for group 8: 0.7045951859956237\n",
      "Test score for group 9: 0.7583892617449665\n",
      "Test score for group 9: 0.9310924369747899\n",
      "Test score for group 9: 0.9663865546218487\n",
      "Test score for group 9: 0.9680672268907563\n",
      "Test score for group 9: 0.8504201680672269\n",
      "Test score for group 10: 0.5629139072847682\n",
      "Test score for group 10: 0.7781456953642384\n",
      "Test score for group 10: 0.8355408388520972\n",
      "Test score for group 10: 0.7955801104972375\n",
      "Test score for group 10: 0.6044198895027625\n"
     ]
    }
   ],
   "source": [
    "#個人特化モデルの評価\n",
    "groups = np.array(groups)\n",
    "\n",
    "# 各個人のデータに対して層化交差検証を適用し\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "for group in np.unique(groups):\n",
    "    group_X = X[groups == group]\n",
    "    group_y = y[groups == group]\n",
    "    \n",
    "    for train_index, test_index in skf.split(group_X, group_y, groups=groups[groups == group]):\n",
    "        X_train, X_test = group_X[train_index], group_X[test_index]\n",
    "        y_train, y_test = group_y[train_index], group_y[test_index]\n",
    "    \n",
    "        clf.fit(X_train, y_train)\n",
    "    \n",
    "        score = clf.score(X_test, y_test)\n",
    "        print(f\"Test score for group {group}: {score}\")\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # 保存\n",
    "        all_y_true.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[7798  174   37   72   72  448  228]\n",
      " [ 242 2953   50  949   57  294  551]\n",
      " [  51   99  732   46   56  436   46]\n",
      " [  93  529   29 2557   13   31  129]\n",
      " [  49   93   44   83 9918  619   14]\n",
      " [ 329  179  180    9  525 7572  286]\n",
      " [ 448  460   36  124    2  452 5103]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         lab       0.87      0.88      0.87      8829\n",
      "        hall       0.66      0.58      0.62      5096\n",
      "    elevator       0.66      0.50      0.57      1466\n",
      "      stairs       0.67      0.76      0.71      3381\n",
      "    outdoors       0.93      0.92      0.92     10820\n",
      "       store       0.77      0.83      0.80      9080\n",
      "      toilet       0.80      0.77      0.79      6625\n",
      "\n",
      "    accuracy                           0.81     45297\n",
      "   macro avg       0.76      0.75      0.75     45297\n",
      "weighted avg       0.81      0.81      0.81     45297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_y_true = le2.inverse_transform(np.array(all_y_true).astype(np.int32))\n",
    "all_y_pred = le2.inverse_transform(np.array(all_y_pred).astype(np.int32))\n",
    "\n",
    "# 全ユーザの結果に基づく混同行列と分類レポートを表示\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_y_true, all_y_pred, labels=target_names))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_y_true, all_y_pred, labels=target_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
